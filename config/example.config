// Update example nextflow config file for the BENGAL pipeline
// Yuyao Song <ysong@ebi.ac.uk>
// Oct 2023

// sections marked with CHANGE should be adjusted as per execution

// CHANGE: directories for project root, work and results 

projectDir='/some/software/dir/BENGAL'
workDir='/some/result/dir/work'
params.results='/some/result/dir/results'

// CHANGE: params specific to dataset, please change according to your task
// input variables

// if each data is batchy, set batch_key to actual batch
// if each data does not appear bachy and cell type between batches are balanced, set batch_key to species_key

// which column stores batch to integrate
params.batch_key='species'

// which column stores species names
params.species_key='species'

// which column specifies cell types matched between species
params.cluster_key='cell_ontology_mapped'

// which column stores cell types to perform SCCAF assessment, usually same with cluster_key
params.cluster_key_sccaf='cell_ontology_mapped'

// which column stores cell types to perform SCCAF annotation transfer, usually same with cluster_key
params.projection_key_sccaf='cell_ontology_mapped'

// input metadata file that maps species names to the respective raw count .h5ad files
params.input_metadata='/some/data/dir/example_metadata_nf.tsv'

// set task name to metadata file basename
params.task_name='example_metadata_nf'


// CHANGE: cluster execution

process.executor = 'lsf'
executor {
    name = 'lsf'
    queueSize = 2000
}

// enable use of conda envs
// conda.enabled = true

// CHANGE: singularity container paths and cluster resource options

singularity {
    enabled = true
}

process {
    withName: validate_adata_input {
        container = "/some/containers/dir/bengal_py.sif"
    }
    withLabel: concat {
        container = "/some/containers/dir/bengal_concat.sif"
    }
    withLabel: scanpy_based {
    // container
    }
    withLabel: 'seurat_based|R_based' {
    // container
    }
    withLabel: scvi_based {
    // container
    }
    withLabel: scIB_based {

    }
    withLabel: regular_resource {
        cpus = 4
        queue = 'research'
        memory = '40GB'
        cache = 'lenient'
    }
    withLabel: regular_intg_resource {
        cpus 12
        queue 'research'
        memory '200GB'
        cache 'lenient'
    }
    withLabel: bigmem_intg_resource {
        cpus = 12
        queue = 'bigmem'
        memory = '400GB'
        cache = 'lenient'
    }
    withLabel: GPU_intg_resource {
        queue 'gpu'
        clusterOptions ' -gpu "num=2:j_exclusive=no" -P gpu -n 4 '
        memory '50GB'
        cache 'lenient'
    }

}


// params for pipeline, no need to change from here onwards

params.liger_metadata="${params.results}/results/rligerUINMF/h5ad_homology_concat/metadata_nf.tsv"
params.homology_concat_h5ad="${params.results}/results/h5ad_homology_concat/*.h5ad"
params.homology_concat_h5seurat="${params.results}/results/h5ad_homology_concat/*.h5seurat"
params.integrated_h5ad="${params.results}/results/*/cross_species/integrated_h5ad/*.h5ad"

// nextflow trace settings, get run stats by adding -with-trace upon execution

trace {
    enabled = true
    file = "${params.results}/nf_trace/example_metadata_nf_trace.txt"
    fields = 'task_id,hash,native_id,name,status,exit,submit,duration,realtime,%cpu,peak_rss,peak_vmem,rchar,wchar'
}

